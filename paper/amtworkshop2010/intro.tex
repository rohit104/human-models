\section{Introduction}
Probabilistic topic models have become popular tools for the
unsupervised analysis of large document
collections~\cite{deerwester-90,griffiths02probabilistic,blei-09}.
These models posit a set of latent \emph{topics}, multinomial
distributions over words, and assume that each document can be
described as a mixture of these topics.  With algorithms for fast
approximate posterior inference, we can use topic models to discover
both the topics and an assignment of topics to documents from a
collection of documents.  (See \myfig{fig:nyttopics:big}.)

These modeling assumptions are useful in the sense that, empirically,
they lead to good models of documents~\cite{wallach-09}.  However,
recent work has explored how these assumptions correspond to humans'
understanding of language~\cite{Chang:2009fk,griffiths-06,mei-07}.  Focusing
on the latent space, i.e., the inferred mappings between topics and
words and between documents and topics, this work has discovered that
although there are some suggestive correspondences between human
semantics and topic models, they are often discordant.

In this paper we build on this work to further explore how humans
relate to topic models.  But whereas previous work has focused on
the results of topic models, here we focus on the process by which
these models are learned.  Topic models lend themselves to sequential
procedures through which the latent space is inferred; these
procedures are in effect programmatic encodings of the modeling
assumptions.  By substituting key steps in this program with human
judgments, we obtain insights into the semantic model conceived by
humans.

Here we present a novel task, \emph{tag-and-cluster}, which asks
subjects to simultaneously annotate a document and cluster that
annotation.  This task simulates the sampling step of the collapsed
Gibbs sampler (described in the next section), except that the
posterior defined by the model has been replaced by human judgments.
The task is quick to complete and is robust against noise.  We report
the results of a large-scale human study of this task, and show that
humans are indeed able to construct a topic model in this fashion, and
that the learned topic model has semantic properties distinct from
existing topic models.  We also demonstrate that the judgments can be
used to guide computer-learned topic models towards models which are
more concordant with human intuitions.
